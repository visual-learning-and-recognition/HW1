{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Simple CNN network for PASCAL multi-label classification (20 points)\n",
    "Now let’s try to recognize some natural images. We provided some starter code for this task. The following steps will guide you through the process.\n",
    "\n",
    "\n",
    "## 1.1 Setup the dataset\n",
    "We start by modifying the code to read images from the PASCAL 2007 dataset. The important thing to note is that PASCAL can have multiple objects present in the same image. Hence, this is a multi-label classification problem, and will have to be tackled slightly differently.\n",
    "\n",
    "\n",
    "First, download the data. `cd` to a location where you can store 0.5GB of images. Then run:\n",
    "```\n",
    "wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
    "tar -xf VOCtrainval_06-Nov-2007.tar\n",
    "\n",
    "wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
    "tar -xf VOCtest_06-Nov-2007.tar\n",
    "cd VOCdevkit/VOC2007/\n",
    "```\n",
    "\n",
    "## 1.2 Write a dataloader with data augmentation (5 pts)\n",
    "**Dataloader** The first step is to write a [pytorch data loader](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html) which loads this PASCAL data. Complete the functions `preload_anno` and `__getitem__` in `voc_dataset.py`. \n",
    "* **Hint**: Refer to the `README` in `VOCdevkit` to understand the structure and labeling.\n",
    "* **Hint** : As the function docstring says, `__getitem__` takes as input the index, and returns a tuple - `(image, label, weight)`. The labels should be 1s for each object that is present in the image, and weights should be 1 for each label in the image, except those labeled as ambiguous (use the `difficult` attribute). All other values should be 0. For simplicity, resize all images to a canonical size.)\n",
    "\n",
    "\n",
    "**Data Augmentation** Modify `__getitem__` to randomly *augment* each datapoint. Please describe what data augmentation you implement.\n",
    "* **Hint**: Since we are training a model from scratch on this small dataset, it is important to perform basic data augmentation to avoid overfitting. Add random crops and left-right flips when training, and do a center crop when testing, etc. As for natural images, another common practice is to subtract the mean values of RGB images from ImageNet dataset. The mean values for RGB images are: `[123.68, 116.78, 103.94]` – sometimes, rescaling to `[−1, 1]` suffices.\n",
    "\n",
    "**Note:** You should use data in ‘trainval’ for training and ‘test’ for testing, since PASCAL is a small dataset.\n",
    "\n",
    "\n",
    "### DESCRIBE YOUR AUGMENTATION PIPELINE HERE**\n",
    "**Train Augmentations:**\n",
    "\n",
    "<br>\n",
    "\n",
    "**Test Augmentations:**\n",
    "\n",
    "\n",
    "## 1.3 Measure Performance (5 pts)\n",
    "To evaluate the trained model, we will use a standard metric for multi-label evaluation - [mean average precision (mAP)](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html). Please implement `eval_dataset_map` in `utils.py` - this function will evaluate a model's map score using a given dataset object. You will need to make predictions on the given dataset with the model and call `compute_ap` to get average precision.\n",
    "\n",
    "\n",
    "Please describe how to compute AP for each class(not mAP).\n",
    "**YOUR ANSWER HERE**\n",
    "\n",
    "\n",
    "## 1.4 Let's Start Training! (5 pts)\n",
    "Write the code for training and testing for multi-label classification in `trainer.py`. To start, you'll use the same model you used for Fashion MNIST (bad idea, but let’s give it a shot).\n",
    "\n",
    "Initialize a fresh model and optimizer. Then run your training code for 5 epochs and print the mAP on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import trainer\n",
    "from utils import ARGS\n",
    "from simple_cnn import SimpleCNN\n",
    "from voc_dataset import VOCDataset\n",
    "\n",
    "# create hyperparameter argument class\n",
    "args = ARGS(epochs=5)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializes (your) naiive model\n",
    "model = SimpleCNN(num_classes=len(VOCDataset.CLASS_NAMES), inp_size=64, c_dim=3)\n",
    "# initializes Adam optimizer and simple StepLR scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "# trains model using your training code and reports test map\n",
    "test_ap, test_map = trainer.train(args, model, optimizer, scheduler)\n",
    "print('test map:', test_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TensorBoard](https://www.tensorflow.org/guide/summaries_and_tensorboard) is an awesome visualization tool. It was firstly integrated in [TensorFlow](https://www.tensorflow.org/) (~possibly the only useful tool TensorFlow provides~). It can be used to visualize training losses, network weights and other parameters.\n",
    "\n",
    "To use TensorBoard in Pytorch, there are two options: [TensorBoard in Pytorch](https://pytorch.org/docs/stable/tensorboard.html) (for Pytorch >= 1.1.0) or [TensorBoardX](https://github.com/lanpa/tensorboardX) - a third party library. Add code in `trainer.py` to visualize the testing MAP and training loss in Tensorboard. *You may have to reload the kernel for these changes to take effect*\n",
    "\n",
    "Show clear screenshots of the learning curves of testing MAP and training loss for 5 epochs (batch size=20, learning rate=0.001). Please evaluate your model to calculate the MAP on the testing dataset every 100 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ARGS(epochs=5, batch_size=20, lr=0.001)\n",
    "model = SimpleCNN(num_classes=len(VOCDataset.CLASS_NAMES), inp_size=64, c_dim=3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "test_ap, test_map = trainer.train(args, model, optimizer, scheduler)\n",
    "print('test map:', test_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INSERT YOUR TENSORBOARD SCREENSHOTS HERE**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
